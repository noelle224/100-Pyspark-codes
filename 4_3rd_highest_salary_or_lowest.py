# -*- coding: utf-8 -*-
"""4. 3rd highest salary or lowest

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pWXP0lsP4ivcktzLXDOfFFRyHUfeuF26
"""

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

# Start Spark session
spark = SparkSession.builder.appName("Employees").getOrCreate()

# Define schema
schema = StructType([
    StructField("emp_id", IntegerType(), True),
    StructField("emp_name", StringType(), True),
    StructField("salary", IntegerType(), True),
    StructField("dep_id", IntegerType(), True),
    StructField("dep_name", StringType(), True)
])

# Create employee data
data = [
    (1, 'Ankit', 14300, 100, 'Analytics'),
    (3, 'Vikas', 12100, 100, 'Analytics'),
    (4, 'Rohit', 7260, 100, 'Analytics'),
    (5, 'Agam', 15600, 200, 'IT'),
    (6, 'Mudit', 15000, 200, 'IT'),
    (2, 'Mohit', 14000, 200, 'IT'),
    (7, 'Sanjay', 12000, 200, 'IT'),
    (8, 'Ashish', 7200, 200, 'IT'),
    (10, 'Rakesh', 8000, 300, 'HR'),
    (9, 'Mukesh', 7000, 300, 'HR'),
    (11, 'Akhil', 4000, 500, 'Ops')
]

# Create DataFrame
df = spark.createDataFrame(data, schema=schema)

# Show the DataFrame
df.show()

from pyspark.sql import Window
from pyspark.sql.functions import col, rank, dense_rank, row_number, count

def additional_fields(df):
  windowspec1 = Window.partitionBy(col('dep_name')).orderBy(col('salary').desc())
  windowspec2 = Window.partitionBy(col('dep_name')).orderBy(col('salary'))
  windowspec_count = Window.partitionBy("dep_name")

  df = df.withColumn('max_salary', rank().over(windowspec1))
  df = df.withColumn('min_salary', dense_rank().over(windowspec2))
  df = df.withColumn("total_count", count("*").over(windowspec_count))
  return df

def final_result(df):
  df = df.filter(((col('total_count') >= 3) & (col('max_salary') == 3)) | ((col('total_count') < 3) & (col('min_salary') == 1)))
  df = df.select('emp_id', 'emp_name', 'salary', 'dep_name')
  return df

df = additional_fields(df)
df = final_result(df)
df.show()